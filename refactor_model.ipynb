{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd05a38-e194-45ce-af84-7e8277df53d5",
   "metadata": {},
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09a457-f05a-474c-ba3f-c5b51be5eb2d",
   "metadata": {},
   "source": [
    "2/22時点でののmodel.py([taro-kuroda-5228/auto_trading_submodule](https://github.com/taro-kuroda-5228/auto_trading_submodule))のModelクラスのリファクタリングを行う。\n",
    "\n",
    "観点は下記の通り。\n",
    "\n",
    "- Modelクラスの責務を分割\n",
    "- DRY\n",
    "- モデル選択を行えるクラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4bdb4b-4f98-46ac-b1a9-241cbfbc20db",
   "metadata": {},
   "source": [
    "# auto_trading_submoduleの概要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d672b55-a15e-4a47-a13d-619f43ac683d",
   "metadata": {},
   "source": [
    "auto_trading_submoduleでは、Yahoo Finance API2を使用して、将来（明日、1週間後、1ヶ月後）の株価のup/downを予測する。\n",
    "\n",
    "株価を予測するまでの概要は下記の通りである。\n",
    "\n",
    "1. 予測対象となる銘柄と、上場国を指定 -> Nameクラス\n",
    "2. Yahoo Financeより、予測したい銘柄の株価情報（始値、終値、安値、高値、出来高）を取得 -> Symbol Dataクラス\n",
    "3. 2で取得したデータをテーブルデータに整形 -> Raw Dataクラス\n",
    "4. 予測したい銘柄の特徴量のテーブルデータを作成するために、1~3を実行\n",
    "5. 予測したい銘柄、特徴量のテーブルデータを結合しデータマートを作成 -> Datamartクラス\n",
    "6. データマートから学習・検証データセットを作成\n",
    "7. 各データセットで学習済みモデル、予測値を算出 -> Modelクラス\n",
    "8. 予測値を使用して、評価指標を算出 -> Scoreクラス\n",
    "9. 最良の評価指標を算出した学習済みモデルを選択 -> Model Selectionクラス\n",
    "10. 9の学習済みモデル使用して、将来の株価のup/downを予測する。-> TODO: future coding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8e1db-01bb-4290-ac1b-46443ed093b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145c0733-d8af-4491-af58-0e822edf25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from datamart import Datamart\n",
    "from feature import Feature\n",
    "from name import Name\n",
    "from raw_data import RawData\n",
    "from symbol_data import SymbolData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ca54d-07c0-4059-882b-e1b90bbbc5c6",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dd529-ba8a-4018-b579-c27f4718f921",
   "metadata": {
    "tags": []
   },
   "source": [
    "## データマート作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e039bf95-8db1-4577-a0d9-0b647baf0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datamart(name: str) -> pd.DataFrame:\n",
    "    \"\"\"終値 x 5日分のラグ x 1日後の予測のためのデータマート作成\"\"\"\n",
    "    symbol_data = SymbolData(name).symbol_data\n",
    "    raw_data = RawData(symbol_data).raw_data\n",
    "    return Datamart(raw_data, \"close\", 5, 1, name).datamart\n",
    "\n",
    "\n",
    "datamart_msft = create_datamart(\"msft\")\n",
    "datamart_dia = create_datamart(\"dia\")\n",
    "datamart_spy = create_datamart(\"spy\")\n",
    "\n",
    "datamart = pd.concat(\n",
    "    [\n",
    "        datamart_msft,\n",
    "        datamart_dia.drop(\"target\", axis=1),\n",
    "        datamart_spy.drop(\"target\", axis=1),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# NOTE: 使用していない不要なクラスは削除しましょう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ebac7-e5ee-42ce-83f9-daf170d6efe7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7858ea54-9e78-44c1-a879-654e9d9e268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: model.pyにおけるfold_splitなどを分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ac1517-281e-4842-b06e-6578abaf5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def X_y_split(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    \"\"\"データマートを特徴量、目的変数に分割\"\"\"\n",
    "    df = df.iloc[::-1]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df[\"target\"]\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def train_test_time_series_split(\n",
    "    X: pd.DataFrame, y: pd.Series\n",
    ") -> Tuple[list, list, list, list]:\n",
    "    \"\"\"特徴量、目的変数を時系列 x train x testで分割\n",
    "    \n",
    "       Note:\n",
    "           X_y_split関数でデータマートを特徴量と目的変数に分割した後、\n",
    "           特徴量と目的変数を学習データセットと検証データセットに分割する。\n",
    "           さらにこの関数では、学習データセットと検証データセットを5組生成する。\n",
    "           \n",
    "           この関数の具体的な機能は、例えばデータマートの期間が2021/01 ~ 2021/08であり、日次データであるとすれば、\n",
    "               - データセット1（学習データセット1, 検証データセット1） -> 2021/01~2021/03, 2021/04\n",
    "               - データセット1（学習データセット2, 検証データセット2） -> 2021/01~2021/04, 2021/05\n",
    "               - データセット1（学習データセット3, 検証データセット3） -> 2021/01~2021/05, 2021/06\n",
    "               - データセット1（学習データセット4, 検証データセット4） -> 2021/01~2021/06, 2021/07\n",
    "               - データセット1（学習データセット5, 検証データセット5） -> 2021/01~2021/07, 2021/08\n",
    "           という5組のデータセットを生成するという機能である。各学習・検証データセットはそれぞれ、X,yを持つ。\n",
    "           l_X_train, l_X_test, l_y_train, l_y_test\n",
    "    \"\"\"\n",
    "    folds = TimeSeriesSplit(n_splits=5)\n",
    "    l_X_train = []\n",
    "    l_X_test = []\n",
    "    l_y_train = []\n",
    "    l_y_test = []\n",
    "    for train_index, test_index in folds.split(X):\n",
    "        X_train, X_test = (\n",
    "            X.iloc[train_index,],\n",
    "            X.iloc[test_index,],\n",
    "        )\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        l_X_train.append(X_train)\n",
    "        l_X_test.append(X_test)\n",
    "        l_y_train.append(y_train)\n",
    "        l_y_test.append(y_test)\n",
    "    return l_X_train, l_X_test, l_y_train, l_y_test\n",
    "\n",
    "\n",
    "X, y = X_y_split(datamart)\n",
    "l_X_train, l_X_test, l_y_train, l_y_test = train_test_time_series_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a029b-6281-4e9f-a1f3-e18fe1e71f30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## モデル選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a19fce-a168-4cca-8a9b-99ca367b6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"学習・予測\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_str: str,\n",
    "        l_X_train: list,\n",
    "        l_X_test: list,\n",
    "        l_y_train: list,\n",
    "        l_y_test: list,\n",
    "    ):\n",
    "        self.model_str = model_str\n",
    "        self.l_X_train = l_X_train\n",
    "        self.l_X_test = l_X_test\n",
    "        self.l_y_train = l_y_train\n",
    "        self.l_y_test = l_y_test  # NOTE: Modelクラス内では使用しないが、Scoreクラス内で使用する。\n",
    "\n",
    "    @property\n",
    "    def clf(self):\n",
    "        if self.model_str == \"lgb\":\n",
    "            return lgb.LGBMClassifier()\n",
    "        elif self.model_str == \"lr\":\n",
    "            return LogisticRegression(\n",
    "                max_iter=1500\n",
    "            )  # NOTE: 2/22時点でConvergence Warningが送出されないことを確認済み\n",
    "        else:\n",
    "            raise Exception(f\"想定していないモデル({model_str})が指定されています。\")\n",
    "\n",
    "    def main(self) -> Dict[str, list]:\n",
    "        \"\"\"各データセットの学習済みモデル・予測値・予測確率(Positive & Negative *1)・予測確率（Positive *2）を算出。\n",
    "        \n",
    "           Note:\n",
    "               *1, 後続のlog_loss算出に使用\n",
    "               *2, 後続のauc算出に使用\n",
    "        \"\"\"\n",
    "        self.l_clf = []\n",
    "        self.l_pred = []\n",
    "        self.l_prob = []\n",
    "        self.l_prob_posi = []\n",
    "        for X_train, X_test, y_train in zip(\n",
    "            self.l_X_train, self.l_X_test, self.l_y_train\n",
    "        ):\n",
    "            clf = self.clf\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            y_prob = clf.predict_proba(X_test)\n",
    "            y_prob_posi = y_prob[:, 1]\n",
    "            self.l_clf.append(clf)\n",
    "            self.l_pred.append(y_pred)\n",
    "            self.l_prob.append(y_prob)\n",
    "            self.l_prob_posi.append(y_prob_posi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f0eb938-3988-43cb-ba9d-d66bf8b12ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Score:\n",
    "    \"\"\"予測後の評価指標\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, model: Model,\n",
    "    ):\n",
    "        self.model = model\n",
    "\n",
    "    @property\n",
    "    def l_idx_accuracy(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.model.l_y_test, self.model.l_pred):\n",
    "            l.append(accuracy_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_precision(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.model.l_y_test, self.model.l_pred):\n",
    "            l.append(precision_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_recall(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.model.l_y_test, self.model.l_pred):\n",
    "            l.append(recall_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_f1(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.model.l_y_test, self.model.l_pred):\n",
    "            l.append(f1_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_log_loss(self):\n",
    "        l = []\n",
    "        for true, prob in zip(self.model.l_y_test, self.model.l_prob):\n",
    "            l.append(-1 * log_loss(y_true=true, y_pred=prob))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_roc_auc(self):\n",
    "        l = []\n",
    "        for true, prob_posi in zip(self.model.l_y_test, self.model.l_prob_posi):\n",
    "            fpr, tpr, _ = roc_curve(y_true=true, y_score=prob_posi)\n",
    "            l.append(auc(fpr, tpr))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_pr_auc(self):\n",
    "        l = []\n",
    "        for true, prob_posi in zip(self.model.l_y_test, self.model.l_prob_posi):\n",
    "            pr_precision, pr_recall, _ = precision_recall_curve(\n",
    "                y_true=true, probas_pred=prob_posi\n",
    "            )\n",
    "            l.append(auc(pr_recall, pr_precision))\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a7b807-c83b-4f18-b024-8b9365afb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection:\n",
    "    \"\"\"最適なモデル選択\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        l_X_train: list,\n",
    "        l_X_test: list,\n",
    "        l_y_train: list,\n",
    "        l_y_test: list,\n",
    "        *model_str,\n",
    "    ):\n",
    "        self.model_str = list(model_str)\n",
    "        self.l_X_train = l_X_train\n",
    "        self.l_X_test = l_X_test\n",
    "        self.l_y_train = l_y_train\n",
    "        self.l_y_test = l_y_test  # NOTE: Modelクラス内では使用しないが、Scoreクラス内で使用する。\n",
    "\n",
    "        self.l_score = []  # NOTE: あるモデルのScoreインスタンス\n",
    "        self.l_average_score = []  # NOTE: あるモデルが持つ複数の評価指標の平均値\n",
    "        self.l_ensemble_score = []\n",
    "        self.l_l_clf = []  # NOTE: 全ての学習済みモデル\n",
    "\n",
    "        self.n_split = 5\n",
    "\n",
    "    def create_df_idx(self, score: Score):\n",
    "        \"\"\"あるモデルの評価指標のテーブル\"\"\"\n",
    "        v = [getattr(score, attr) for attr in dir(score) if attr.startswith(\"l_idx\")]\n",
    "        idx = [\n",
    "            attr.replace(\"l_idx_\", \"\")\n",
    "            for attr in dir(score)\n",
    "            if attr.startswith(\"l_idx\")\n",
    "        ]\n",
    "        col = [\n",
    "            order for order in range(1, self.n_split + 1)\n",
    "        ]  # NOTE: n_splitはTimeSeriesSplitによる分割回数\n",
    "        return pd.DataFrame(v, index=idx, columns=col)\n",
    "\n",
    "    def create_average_score(self, df_idx):\n",
    "        \"\"\"ある指標の中でどのモデルが良かったかの判断指標\"\"\"\n",
    "        return df_idx.mean(axis=1)\n",
    "\n",
    "    def create_ensemble_score(self, df_idx):\n",
    "        \"\"\"あるモデルの中で何番目の分割が良かったかの判断指標\"\"\"\n",
    "        return df_idx.mean(axis=0)\n",
    "\n",
    "    def _calc(self):\n",
    "        # NOTE: アンダーバー1つはクラス内部用。外部からアクセスしない。\n",
    "        # .      2つは外部からアクセスできない。\n",
    "        \"\"\"最良のモデル選択に使用する評価指標の数値を算出\"\"\"\n",
    "        for model_str in self.model_str:\n",
    "            model = Model(model_str, l_X_train, l_X_test, l_y_train, l_y_test)\n",
    "            model.main()\n",
    "            score = Score(model)\n",
    "            df_idx = self.create_df_idx(score)\n",
    "            average_score = self.create_average_score(df_idx)\n",
    "            ensemble_score = self.create_ensemble_score(df_idx)\n",
    "            self.l_average_score.append(average_score.sum())\n",
    "            self.l_ensemble_score.append(ensemble_score.tolist())\n",
    "            self.l_score.append(score)\n",
    "            self.l_l_clf.append(model.l_clf)\n",
    "\n",
    "    def best_model(self, verbose: bool = False):\n",
    "        self._calc()\n",
    "        max_ = max(self.l_average_score)\n",
    "        self.idx_max_model = self.l_average_score.index(max_)\n",
    "\n",
    "        max_ = max(self.l_ensemble_score[self.idx_max_model])\n",
    "        self.idx_max_split = self.l_ensemble_score[self.idx_max_model].index(max_)\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"\"\"best_model: {self.model_str[self.idx_max_model]}\\nbest_split: {self.idx_max_split}\"\"\"\n",
    "            )\n",
    "\n",
    "        return self.l_l_clf[self.idx_max_model][self.idx_max_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59ca2371-e26a-4ebe-9a62-627351da337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = ModelSelection(l_X_train, l_X_test, l_y_train, l_y_test, \"lgb\", \"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f52196e-cd89-49e1-a7ed-729bdc3b156e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model: lr\n",
      "best_split: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_selection.best_model(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
