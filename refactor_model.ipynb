{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd05a38-e194-45ce-af84-7e8277df53d5",
   "metadata": {},
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09a457-f05a-474c-ba3f-c5b51be5eb2d",
   "metadata": {},
   "source": [
    "2/22時点でのmodel.pyのModelクラスのリファクタリングを行う。観点は下記の通り。\n",
    "\n",
    "- Modelクラスの責務を分割\n",
    "- DRY\n",
    "- モデル選択を行えるクラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8e1db-01bb-4290-ac1b-46443ed093b3",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "145c0733-d8af-4491-af58-0e822edf25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from datamart import Datamart\n",
    "from feature import Feature\n",
    "from name import Name\n",
    "from raw_data import RawData\n",
    "from symbol_data import SymbolData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "fa61fd08-fa4d-4818-a7c7-7606310f530d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datamart(name: str) -> pd.DataFrame:\n",
    "    symbol_data = SymbolData(name).symbol_data\n",
    "    raw_data = RawData(symbol_data).raw_data\n",
    "    return Datamart(raw_data, \"close\", 5, 1, name).datamart\n",
    "\n",
    "\n",
    "def train_test_time_series_split(df: pd.DataFrame):\n",
    "    \"\"\"datamartを時系列 x train x testで分割\"\"\"\n",
    "    df = df.iloc[::-1]\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    X = df.iloc[:, 1:]\n",
    "    y = df[\"target\"]\n",
    "    folds = TimeSeriesSplit(n_splits=5)\n",
    "    l_X_train = []\n",
    "    l_X_test = []\n",
    "    l_y_train = []\n",
    "    l_y_test = []\n",
    "    for train_index, test_index in folds.split(X):\n",
    "        X_train, X_test = (\n",
    "            X.iloc[train_index,],\n",
    "            X.iloc[test_index,],\n",
    "        )\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        l_X_train.append(X_train)\n",
    "        l_X_test.append(X_test)\n",
    "        l_y_train.append(y_train)\n",
    "        l_y_test.append(y_test)\n",
    "    return l_X_train, l_X_test, l_y_train, l_y_test\n",
    "\n",
    "\n",
    "def create_clf_pred_prob_list(\n",
    "    model_str, l_X_train: list, l_X_test: list, l_y_train: list\n",
    ") -> Dict[str, list]:\n",
    "    \"\"\"train_test_time_series_splitの結果を使用して、各データセットのモデル・予測値・予測確率・予測確率（Positive）を算出。\"\"\"\n",
    "    l_clf = []\n",
    "    l_pred = []\n",
    "    l_prob = []\n",
    "    l_prob_posi = []\n",
    "    for X_train, X_test, y_train in zip(l_X_train, l_X_test, l_y_train):\n",
    "        if model_str == \"lgb\":\n",
    "            clf = lgb.LGBMClassifier()\n",
    "        elif model_str == \"lr\":\n",
    "            clf = LogisticRegression(max_iter=1500)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        y_prob = clf.predict_proba(X_test)\n",
    "        y_prob_posi = y_prob[:, 1]\n",
    "        l_clf.append(clf)\n",
    "        l_pred.append(y_pred)\n",
    "        l_prob.append(y_prob)\n",
    "        l_prob_posi.append(y_prob_posi)\n",
    "    return {\"clf\": l_clf, \"pred\": l_pred, \"prob\": l_prob, \"prob_posi\": l_prob_posi}\n",
    "\n",
    "\n",
    "class Score:\n",
    "    def __init__(\n",
    "        self,\n",
    "        l_X_train: list,\n",
    "        l_X_test: list,\n",
    "        l_y_train: list,\n",
    "        l_y_test: list,\n",
    "        l_pred: list,\n",
    "        l_prob: list,\n",
    "        l_prob_posi: list,\n",
    "    ):\n",
    "        self.l_X_train = l_X_train\n",
    "        self.l_X_test = l_X_test\n",
    "        self.l_y_train = l_y_train\n",
    "        self.l_y_test = l_y_test\n",
    "        self.l_pred = l_pred\n",
    "        self.l_prob = l_prob\n",
    "        self.l_prob_posi = l_prob_posi\n",
    "        self.n_split = 5\n",
    "\n",
    "    @property\n",
    "    def l_idx_accuracy(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.l_y_test, self.l_pred):\n",
    "            l.append(accuracy_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_precision(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.l_y_test, self.l_pred):\n",
    "            l.append(precision_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_recall(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.l_y_test, self.l_pred):\n",
    "            l.append(recall_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_f1(self):\n",
    "        l = []\n",
    "        for true, pred in zip(self.l_y_test, self.l_pred):\n",
    "            l.append(f1_score(y_true=true, y_pred=pred))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_log_loss(self):\n",
    "        l = []\n",
    "        for true, prob in zip(self.l_y_test, self.l_prob):\n",
    "            l.append(log_loss(y_true=true, y_pred=prob))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_log_loss(self):\n",
    "        l = []\n",
    "        for true, prob in zip(self.l_y_test, self.l_prob):\n",
    "            l.append(-1 * log_loss(y_true=true, y_pred=prob))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_roc_auc(self):\n",
    "        l = []\n",
    "        for true, prob_posi in zip(self.l_y_test, self.l_prob_posi):\n",
    "            fpr, tpr, _ = roc_curve(y_true=true, y_score=prob_posi)\n",
    "            l.append(auc(fpr, tpr))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def l_idx_pr_auc(self):\n",
    "        l = []\n",
    "        for true, prob_posi in zip(self.l_y_test, self.l_prob_posi):\n",
    "            pr_precision, pr_recall, _ = precision_recall_curve(\n",
    "                y_true=true, probas_pred=prob_posi\n",
    "            )\n",
    "            l.append(auc(pr_recall, pr_precision))\n",
    "        return l\n",
    "\n",
    "    @property\n",
    "    def df_idx(self):\n",
    "        v = [getattr(score, attr) for attr in dir(score) if attr.startswith(\"l_idx\")]\n",
    "        idx = [\n",
    "            attr.replace(\"l_idx_\", \"\")\n",
    "            for attr in dir(score)\n",
    "            if attr.startswith(\"l_idx\")\n",
    "        ]\n",
    "        col = [\n",
    "            order for order in range(1, self.n_split + 1)\n",
    "        ]  # NOTE: n_splitはTimeSeriesSplitによる分割回数\n",
    "        return pd.DataFrame(v, index=idx, columns=col)\n",
    "\n",
    "    @property\n",
    "    def average_score(self):\n",
    "        \"\"\"ある指標の中でどのモデルが良かったかの判断指標\"\"\"\n",
    "        return self.df_idx.mean(axis=1)\n",
    "\n",
    "    @property\n",
    "    def ensemble_score(self):\n",
    "        \"\"\"あるモデルの中で何番目の分割が良かったかの判断指標\"\"\"\n",
    "        return self.df_idx.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ca54d-07c0-4059-882b-e1b90bbbc5c6",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150dd529-ba8a-4018-b579-c27f4718f921",
   "metadata": {},
   "source": [
    "## データマート作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "159a3820-5ae1-446e-addd-a1514b4b1c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart_msft = create_datamart(\"msft\")\n",
    "datamart_dia = create_datamart(\"dia\")\n",
    "datamart_spy = create_datamart(\"spy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8feea35a-41cb-4ba4-8181-9715ffacfe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamart = pd.concat(\n",
    "    [\n",
    "        datamart_msft,\n",
    "        datamart_dia.drop(\"target\", axis=1),\n",
    "        datamart_spy.drop(\"target\", axis=1),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ebac7-e5ee-42ce-83f9-daf170d6efe7",
   "metadata": {},
   "source": [
    "## データセット作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "69ac1517-281e-4842-b06e-6578abaf5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_X_train, l_X_test, l_y_train, l_y_test = train_test_time_series_split(datamart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0a029b-6281-4e9f-a1f3-e18fe1e71f30",
   "metadata": {},
   "source": [
    "## モデル選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e3a7b807-c83b-4f18-b024-8b9365afb0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1500)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_model = [\"lgb\", \"lr\"]\n",
    "\n",
    "l_score = []\n",
    "l_average_score = []\n",
    "ll_clf = []\n",
    "\n",
    "for model in l_model:\n",
    "    d = create_clf_pred_prob_list(model, l_X_train, l_X_test, l_y_train)\n",
    "    l_clf, l_pred, l_prob, l_prob_posi = d[\"clf\"], d[\"pred\"], d[\"prob\"], d[\"prob_posi\"]\n",
    "    score = Score(\n",
    "        l_X_train, l_X_test, l_y_train, l_y_test, l_pred, l_prob, l_prob_posi,\n",
    "    )\n",
    "    l_score.append(score)\n",
    "    l_average_score.append(score.average_score.sum())\n",
    "    ll_clf.append(l_clf)\n",
    "\n",
    "max_ = max(l_average_score)\n",
    "idx_max_model = l_average_score.index(max_)\n",
    "\n",
    "best_model_str = l_model[idx_max_model]\n",
    "best_model_score = l_score[1]\n",
    "\n",
    "s = best_model_score.ensemble_score.tolist()\n",
    "max_ = max(s)\n",
    "idx_max_split = s.index(max_)\n",
    "ll_clf[idx_max_model][idx_max_split]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
